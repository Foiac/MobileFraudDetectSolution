
---> Provisionar Azure Key Vault

kvName="kvfraud"
az keyvault create --name $kvName --resource-group $rgName --location $region

---> Transferir Connection String para uma variável

connectionString=$(az eventhubs namespace authorization-rule keys list --resource-group $rgName --namespace-name $namespaceName --name $policieName --query primaryConnectionString --output tsv)

---> Alterar role de usuário para ter acesso ao key vault

az role assignment create --assignee kaio_cfs_hotmail.com#EXT#@kaiocfshotmail.onmicrosoft.com --role "Key Vault Administrator" --scope /subscriptions/$subsId/resourceGroups/$rgName/providers/Microsoft.KeyVault/vaults/$kvName

---> Armazenar Connection Strig no Key Vault

secretName="ehcssecret"
az keyvault secret set --vault-name $kvName --name $secretName --value $connectionString

---> Criar Scope no Databricks com secret criada

scopeName="dbwsscope"
kvName="kvfraud"
databricks secrets create-scope --scope $scopeName --scope-backend-type AZURE_KEYVAULT --resource-id $kvName --dns-name https://kvfraud.vault.azure.net

---> Instalar Coordinates Maven no databricks

com.microsoft.azure:azure-eventhubs-spark_2.12:2.3.22

---> Provisionar ADLS na azure:

storageAcName="stacfraud"
az storage account create --name $storageAcName --resource-group $rgName --location $region --sku Standard_LRS --kind StorageV2 --hierarchical-namespace true

---> Criar Container no ALDS:

containerName="contfraud"
az storage container create --name $containerName --account-name $storageAcName --auth-mode login

---> Criar os diretórios de armazenamento:

az storage fs directory create --account-name $storageAcName --file-system $containerName --name Bronze
az storage fs directory create --account-name $storageAcName --file-system $containerName --name Silver
az storage fs directory create --account-name $storageAcName --file-system $containerName --name Gold


---> Pegar chave de acesso do ADLS:

az storage account keys list --resource-group $rgName --account-name $storageAcName 


---> armazenar connection



---> Provisionar Worksapce do Azure Databricks:

az databricks workspace create --resource-group $rgName --name databricks-fraudDetect --location $region --sku standard

---> Configs do Cluster Databricks:

Nome do cluster: fraud-cluster
Runtime: 13.3 LTS (Scala 2.12, spark 3.4.1)
Worker: Standard_D3_v2, 2 workers
Driver: Standard_D3_v2, 2 workers

---> Workflows:

Nome da tarefa: fraudFastLoad


---> Criar Scope do Databricks para sincronizar com AZURE_KEYVAULT

https://adb-2405977659128258.18.azuredatabricks.net/?o=2405977659128258#secrets/createScope
nome = dbwsscope

---> Apagar Grupo de Recursos:

az group delete --name rgfraud


fs.azure.account.auth.type OAuth
fs.azure.account.oauth.provider.type org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
fs.azure.account.oauth2.client.id 775d1965-2ada-4399-adb9-ead9caaf4d72
fs.azure.account.oauth2.client.secret {{secrets/dbwsscope/spn-secret}}
fs.azure.account.oauth2.client.endpoint https://login.microsoftonline.com/dc25df03-ffa5-4111-b188-46fe6cd26a3a/oauth2/token
